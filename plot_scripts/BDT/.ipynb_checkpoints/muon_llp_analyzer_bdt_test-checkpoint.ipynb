{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosted Decision Tree Test File for AN-19-154 Work\n",
    "\n",
    "# Coders: Nathan Suri, Caltech\n",
    "# Date: September 24, 2019\n",
    "# LPC LLP Group\n",
    "\n",
    "# Description\n",
    "# Study shower shape to improve signal/bkg discrimination\n",
    "\n",
    "# Action Plan\n",
    "# Begin developing simple BDT\n",
    "\n",
    "# Notes/Conclusions\n",
    "# @nasurijr: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Username: nasurijr\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:85% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User specifics\n",
    "# Setups pwd location for data files and imports of special ROOT utilities\n",
    "\n",
    "work_location = input(\"Username: \")\n",
    "if work_location == 'nasurijr':\n",
    "    pwd = '/nfshome/nasurijr/LLP_analysis/delayed_jet_analyzer/'\n",
    "    \n",
    "    # Sets display width\n",
    "    from IPython.core.display import display, HTML\n",
    "    display(HTML(\"<style>.container { width:85% !important; }</style>\"))\n",
    "    \n",
    "# elif work_location == '<Insert Tier2 username here>':\n",
    "#     pwd = '/home/cms/delayed_jet_analyzer/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.18/02\n"
     ]
    }
   ],
   "source": [
    "# Imports necessary utilities and modules\n",
    "\n",
    "import ROOT as rt\n",
    "import root_numpy as rtnp\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "from collections import Counter \n",
    "import datetime\n",
    "import pytz\n",
    "\n",
    "# Graph/histo utilities from ROOT\n",
    "# Contained within the delayed_jet_analyzer repository\n",
    "import sys\n",
    "sys.path.append(pwd+'lib')\n",
    "from histo_utilities import create_TH1D, create_TH2D, create_TGraph, std_color_list\n",
    "\n",
    "# Used for extracting the TTree structure from each datafile\n",
    "import os\n",
    "import uproot\n",
    "\n",
    "# Used for creating user-readable tables\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "# Imports jet clustering algorithm (FastJet)\n",
    "from pyjet import cluster\n",
    "\n",
    "# Imports XGBoost BDT package\n",
    "import xgboost as xgb\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "donotdelete = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-25 16:42:17.311244-07:00\n",
      "WJetsToLNu /nfshome/nasurijr/LLP_analysis/delayed_jet_analyzer/data/WJetsToLNu_TuneCUETP8M1_13TeV-amcatnloFXFX-pythia8_1pb_weighted.root\n",
      "2019-09-25 16:42:17.409001-07:00\n",
      "m55ct10m /nfshome/nasurijr/LLP_analysis/delayed_jet_analyzer/data/WH_HToSSTobbbb_WToLNu_MH-125_MS-55_ctauS-10000_TuneCUETP8M1_13TeV-powheg-pythia8_1pb_weighted.root\n"
     ]
    }
   ],
   "source": [
    "# Setups dictionaries for storing data from MC/data ntuples\n",
    "fpath = {}\n",
    "tree = {}\n",
    "NEvents = {}\n",
    "\n",
    "data_path = pwd+'data/'\n",
    "\n",
    "# Background Samples\n",
    "fpath['WJetsToLNu'] = data_path + 'WJetsToLNu_TuneCUETP8M1_13TeV-amcatnloFXFX-pythia8_1pb_weighted.root'\n",
    "\n",
    "# Signal Samples \n",
    "fpath['m55ct10m'] = data_path + 'WH_HToSSTobbbb_WToLNu_MH-125_MS-55_ctauS-10000_TuneCUETP8M1_13TeV-powheg-pythia8_1pb_weighted.root'\n",
    "\n",
    "for k,v in fpath.items():\n",
    "    print(str(datetime.datetime.now(pytz.timezone('US/Pacific'))))\n",
    "    print(k, v)\n",
    "    root_dir = uproot.open(v) \n",
    "    tree[k] = root_dir['MuonSystem']\n",
    "    NEvents[k] = root_dir['NEvents'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name TTree Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bookkeeping: Defines the TTrees from the read datafiles\n",
    "# Names displayed in README.md table\n",
    "\n",
    "T_m55ct10m = tree['m55ct10m']\n",
    "T_wjets = tree['WJetsToLNu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bookkeeping: Creates a dictionary for iterating over all of the datafiles and \n",
    "#              converting the relevant branches to numpy arrays\n",
    "# Names displayed in README.md table\n",
    "\n",
    "# data_trees = {'m55ct10m_wh_bbbb_minus': T_m55_ct10_minus, 'm55ct10m_wh_bbbb_plus': T_m55_ct10_plus, 'WJetsToLNu': T_wjets, 'm15ct10000mm': T_m15_ct10}\n",
    "\n",
    "data_trees = {'m55ct10m': T_m55ct10m, 'WJetsToLNu': T_wjets}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and Store Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable Definitions\n",
    "# Creates dictionaries for variables to be analyzed\n",
    "# The dictionaries will contain the variable arrays for each datafile with a relevant key\n",
    "\n",
    "# General Information\n",
    "eventNum = {}\n",
    "lumiNum = {}\n",
    "weight = {}\n",
    "\n",
    "# Standard CSC vars\n",
    "nCsc = {}\n",
    "csc_z = {}\n",
    "csc_x = {}\n",
    "csc_y = {}\n",
    "csc_eta = {}\n",
    "csc_phi = {}\n",
    "csc_t = {}\n",
    "csc_r = {}\n",
    "nCsc_pop = {}\n",
    "\n",
    "# CSC Vectors\n",
    "csc_dir_x = {}\n",
    "csc_dir_y = {}\n",
    "csc_dir_z = {}\n",
    "\n",
    "# Boolean Vetoes\n",
    "nCsc_jet_veto = {}\n",
    "nCsc_combo_veto = {}\n",
    "\n",
    "# Shower Shape\n",
    "csc_cluster_x = {}\n",
    "csc_cluster_y = {}\n",
    "csc_cluster_z = {}\n",
    "csc_cluster_t = {}\n",
    "csc_cluster_eta = {}\n",
    "csc_cluster_phi = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 2019-09-25 16:42:18.122610-07:00\n",
      "m55ct10m: 2019-09-25 16:42:18.240564-07:00\n",
      "WJetsToLNu: 2019-09-25 16:42:24.867056-07:00\n"
     ]
    }
   ],
   "source": [
    "print('Start: ' + str(datetime.datetime.now(pytz.timezone('US/Pacific'))))\n",
    "\n",
    "for species, arbor in data_trees.items():\n",
    "    \n",
    "    # General Information\n",
    "    eventNum[species] = arbor['evtNum'].array()\n",
    "    lumiNum[species] = arbor['lumiSec'].array()\n",
    "    weight[species] = arbor['weight'].array()\n",
    "    \n",
    "    # Standard CSC vars\n",
    "    nCsc[species] = arbor['nCsc'].array()\n",
    "    nCsc_pop[species] = arbor['cscClusterSize'].array()\n",
    "    csc_z[species] = arbor['cscZ'].array()\n",
    "    csc_x[species] = arbor['cscX'].array()\n",
    "    csc_y[species] = arbor['cscY'].array()\n",
    "    csc_t[species] = arbor['cscT'].array()\n",
    "    csc_eta[species] = arbor['cscEta'].array()\n",
    "    csc_phi[species] = arbor['cscPhi'].array()\n",
    "        \n",
    "    # CSC Vectors\n",
    "    csc_dir_x[species] = arbor['cscDirectionX'].array()\n",
    "    csc_dir_y[species] = arbor['cscDirectionY'].array()\n",
    "    csc_dir_z[species] = arbor['cscDirectionZ'].array()\n",
    "    \n",
    "    # Boolean Vetoes\n",
    "    nCsc_jet_veto[species] = arbor['nCsc_JetVetoCluster0p4_Me1112Veto'].array()\n",
    "    nCsc_combo_veto[species] = arbor['nCsc_JetMuonVetoCluster0p4_Me1112Veto'].array()\n",
    "    \n",
    "    # Shower Shape\n",
    "    csc_cluster_x[species] = arbor['cscClusterXSpread'].array().flatten()\n",
    "    csc_cluster_y[species] = arbor['cscClusterYSpread'].array().flatten()\n",
    "    csc_cluster_z[species] = arbor['cscClusterZSpread'].array().flatten()\n",
    "    csc_cluster_t[species] = arbor['cscClusterTimeSpread'].array().flatten()\n",
    "    csc_cluster_eta[species] = arbor['cscClusterEtaSpread'].array().flatten()\n",
    "    csc_cluster_phi[species] = arbor['cscClusterPhiSpread'].array().flatten()\n",
    "    \n",
    "    print(species + ': ' +str(datetime.datetime.now(pytz.timezone('US/Pacific'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BDT Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to DMatrix Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Combine signal and background arrays\n",
    "\n",
    "csc_cluster_x['input'] = np.concatenate((csc_cluster_x['m55ct10m'], csc_cluster_x['WJetsToLNu']))\n",
    "csc_cluster_y['input'] = np.concatenate((csc_cluster_y['m55ct10m'], csc_cluster_y['WJetsToLNu']))\n",
    "csc_cluster_z['input'] = np.concatenate((csc_cluster_z['m55ct10m'], csc_cluster_z['WJetsToLNu']))\n",
    "csc_cluster_t['input'] = np.concatenate((csc_cluster_t['m55ct10m'], csc_cluster_t['WJetsToLNu']))\n",
    "csc_cluster_eta['input'] = np.concatenate((csc_cluster_eta['m55ct10m'], csc_cluster_eta['WJetsToLNu']))\n",
    "csc_cluster_phi['input'] = np.concatenate((csc_cluster_phi['m55ct10m'], csc_cluster_phi['WJetsToLNu']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Label signal and background data points\n",
    "\n",
    "csc_cluster_label = np.concatenate((np.full(len(csc_cluster_x['m55ct10m']), True), np.full(len(csc_cluster_x['WJetsToLNu']), False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Gather all feature names\n",
    "\n",
    "csc_cluster_features = ['cscClusterXSpread', 'cscClusterYSpread', 'cscClusterZSpread', 'cscClusterTimeSpread', 'cscClusterEtaSpread', 'cscClusterPhiSpread']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Construct 2D Numpy data array\n",
    "\n",
    "data_bdt = np.dstack((csc_cluster_x['input'], csc_cluster_y['input'], csc_cluster_z['input'], csc_cluster_t['input'], csc_cluster_eta['input'], csc_cluster_phi['input'], csc_cluster_label))[0]\n",
    "np.random.shuffle(data_bdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Define training and testing sets\n",
    "\n",
    "data_train = data_bdt[:384552]\n",
    "data_test = data_bdt[384552:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/xgboost/core.py:614: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"because it will generate extra copies and increase memory consumption\")\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Convert np.arrays into DMatrix format\n",
    "\n",
    "# train = data_train[:,0:-1]\n",
    "# test = data_test[:,0:-1]\n",
    "\n",
    "train = xgb.DMatrix(data = data_train[:,0:-1],label=data_train[:,-1], missing=-999.0,feature_names=csc_cluster_features)\n",
    "test = xgb.DMatrix(data = data_test[:,0:-1],label=data_train[:,-1], missing=-999.0,feature_names=csc_cluster_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Hyperparameters and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {}\n",
    "\n",
    "# Booster parameters\n",
    "param['eta']              = 0.3 # learning rate\n",
    "param['max_depth']        = 5  # maximum depth of a tree\n",
    "param['subsample']        = 0.2 # fraction of events to train tree on\n",
    "param['colsample_bytree'] = 0.5 # fraction of features to train tree on\n",
    "\n",
    "# Learning task parameters\n",
    "param['objective']   = 'binary:logistic' # objective function\n",
    "param['eval_metric'] = 'error'           # evaluation metric for cross validation\n",
    "param['nthreads'] = 4\n",
    "param = list(param.items()) + [('eval_metric', 'logloss')] + [('eval_metric', 'rmse')]\n",
    "\n",
    "num_trees = 50  # number of trees to make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 2019-09-25 16:42:26.660631-07:00\n",
      "End: 2019-09-25 16:42:34.050878-07:00\n"
     ]
    }
   ],
   "source": [
    "print('Start: ' +str(datetime.datetime.now(pytz.timezone('US/Pacific'))))\n",
    "booster = xgb.train(param,train,num_boost_round=num_trees)\n",
    "print('End: ' +str(datetime.datetime.now(pytz.timezone('US/Pacific'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = booster.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all predictions (both signal and background)\n",
    "plt.figure();\n",
    "plt.hist(predictions,bins=np.linspace(0,1,50),histtype='step',color='darkgreen',label='All events');\n",
    "# make the plot readable\n",
    "plt.xlabel('Prediction from BDT',fontsize=12);\n",
    "plt.ylabel('Events',fontsize=12);\n",
    "plt.legend(frameon=False);\n",
    "\n",
    "# # plot signal and background separately\n",
    "# plt.figure();\n",
    "# plt.hist(predictions[test.get_label().astype(bool)],bins=np.linspace(0,1,50),\n",
    "#          histtype='step',color='midnightblue',label='signal');\n",
    "# plt.hist(predictions[~(test.get_label().astype(bool))],bins=np.linspace(0,1,50),\n",
    "#          histtype='step',color='firebrick',label='background');\n",
    "# # make the plot readable\n",
    "# plt.xlabel('Prediction from BDT',fontsize=12);\n",
    "# plt.ylabel('Events',fontsize=12);\n",
    "# plt.legend(frameon=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
